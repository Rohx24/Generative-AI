{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5IHEN2hi95A",
        "outputId": "c8863301-e1e5-480d-989b-2c0927f59ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/108.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.2/490.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade langchain langchain-core langchain-groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter GROQ_API_KEY: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6kdDPmbluMD",
        "outputId": "ccc51d69-35ad-4fbc-f989-f139b7ecde5f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter GROQ_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",   # other options below\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"\"\"\n",
        "Explain {topic} in simple words for a university lab record.\n",
        "\n",
        "Include:\n",
        "1) Definition (2-3 lines)\n",
        "2) One real-life example\n",
        "3) Simple working steps (4-5)\n",
        "4) 5 practice questions\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "res = chain.invoke({\"topic\": \"LangChain\"})\n",
        "print(res.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyLWlKzwlytr",
        "outputId": "5587ece8-4527-40fe-bc55-5c3bfbf0dca8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Lab Record: LangChain**\n",
            "\n",
            "**Definition:**\n",
            "LangChain is an open-source, Python-based framework that enables developers to build conversational AI models by combining multiple AI technologies, such as natural language processing (NLP), machine learning, and knowledge graph databases. It allows for the creation of complex, multi-step conversations and provides a flexible way to integrate different AI components.\n",
            "\n",
            "**Real-Life Example:**\n",
            "Imagine building a conversational AI chatbot for a customer support service. LangChain can be used to create a chatbot that not only answers customer queries but also retrieves relevant information from a knowledge graph database, generates personalized responses, and even integrates with external APIs to fetch additional data.\n",
            "\n",
            "**Simple Working Steps:**\n",
            "\n",
            "1. **Define the conversation flow**: Determine the sequence of events and interactions that will occur during the conversation.\n",
            "2. **Choose AI components**: Select the relevant NLP, machine learning, and knowledge graph database components to be used in the conversation.\n",
            "3. **Integrate components**: Use LangChain's APIs to integrate the chosen components and create a cohesive conversation flow.\n",
            "4. **Train and fine-tune models**: Train and fine-tune the AI models to ensure they are accurate and effective.\n",
            "5. **Deploy and test**: Deploy the conversational AI model and test its performance in a real-world setting.\n",
            "\n",
            "**Practice Questions:**\n",
            "\n",
            "1. What is the primary purpose of LangChain in conversational AI development?\n",
            "a) To build simple chatbots\n",
            "b) To integrate multiple AI technologies\n",
            "c) To create complex, multi-step conversations\n",
            "d) To deploy AI models\n",
            "\n",
            "Answer: c) To create complex, multi-step conversations\n",
            "\n",
            "2. Which of the following is a key feature of LangChain?\n",
            "a) It only supports NLP-based conversations\n",
            "b) It provides a flexible way to integrate different AI components\n",
            "c) It is only suitable for small-scale conversations\n",
            "d) It is a proprietary framework\n",
            "\n",
            "Answer: b) It provides a flexible way to integrate different AI components\n",
            "\n",
            "3. What is the role of a knowledge graph database in LangChain-based conversations?\n",
            "a) To store user data\n",
            "b) To retrieve relevant information for conversation\n",
            "c) To generate personalized responses\n",
            "d) To deploy AI models\n",
            "\n",
            "Answer: b) To retrieve relevant information for conversation\n",
            "\n",
            "4. Which of the following is a benefit of using LangChain in conversational AI development?\n",
            "a) It reduces development time\n",
            "b) It increases development complexity\n",
            "c) It improves model accuracy\n",
            "d) It reduces model flexibility\n",
            "\n",
            "Answer: a) It reduces development time\n",
            "\n",
            "5. What is the primary advantage of LangChain's open-source nature?\n",
            "a) It is proprietary and exclusive\n",
            "b) It is free to use and modify\n",
            "c) It is only suitable for large-scale conversations\n",
            "d) It is only available for Windows operating systems\n",
            "\n",
            "Answer: b) It is free to use and modify\n"
          ]
        }
      ]
    }
  ]
}